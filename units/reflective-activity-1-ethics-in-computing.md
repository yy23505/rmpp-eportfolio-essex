---
layout: default
title: "Reflective Activity 1 — Ethics in Computing"
permalink: /units/reflective-activity-1-ethics-in-computing/
---

# Reflective Activity 1 — Ethics in Computing in the Age of Generative AI

![Banner: Ethics in AI and technology]({{ "/assets/images/ethics-banner.jpg" | relative_url }}){: .unit-banner }

_Programme: MSc Computer Science (University of Essex Online)_  
_Module: Research Methods & Professional Practice_

---

## Introduction

The resurgence of artificial intelligence (AI) in recent years has ushered in transformative changes across numerous sectors, with **generative AI** technologies at the forefront. Tools capable of producing text, images, audio, and code, such as ChatGPT and Midjourney, have rapidly shifted the landscape of computing and society. These advancements, while promising, raise significant ethical concerns that demand careful consideration.  

As Deckard (2023) notes, ethics in AI extends beyond technical capabilities to moral responsibilities that guide its design and use. Correa et al. (2023) further highlight the global proliferation of AI ethics guidelines, yet they note a persistent lack of consensus on actionable standards. This reflection explores the ethical challenges posed by generative AI, reviews international approaches to AI governance, and proposes a multi-layered framework for ethical computing.

---

## Ethical Challenges in Generative AI

Generative AI systems present several ethical dilemmas with far-reaching implications.

### Bias and Discrimination  
AI models often inherit societal biases embedded in their training data, which can reinforce stereotypes in sectors like hiring, policing, and healthcare (Correa et al., 2023; Hagendorff, 2024). Without mitigation, generative AI can exacerbate social inequalities by producing outputs that disadvantage marginalised communities.

### Misinformation and Privacy  
Generative AI can create highly convincing but false content, including deepfakes and fabricated news articles, which threaten public trust and social cohesion (Radanliev et al., 2025). Privacy concerns also arise because AI models frequently rely on personal or sensitive data. Even when anonymised, such data can be reverse-engineered, raising risks for surveillance and misuse (Al-kfairy, 2024).

### Intellectual Property and Labour Impact  
AI-generated content is often derivative of copyrighted works, raising questions about ownership, compensation, and creative recognition (Dwivedi et al., 2023). Automation through generative AI could also displace jobs, especially in creative and knowledge-based industries, underscoring the need for policies that mitigate social and economic harms (Papagiannidis et al., 2025).

---

## Global Perspectives on AI Ethics

Correa et al. (2023) reviewed over 200 AI ethics guidelines worldwide, revealing major disparities in governance approaches:

- **European Union (EU):** Risk-based and precautionary (AI Act).  
- **United States:** Market-driven and voluntary frameworks (e.g., NIST AI Risk Management Framework).  
- **China:** Centralised, value-driven governance aligned with state priorities.

These contrasting models highlight the complexity of developing a universal ethical framework. While principles such as fairness, transparency, accountability, and safety are widely endorsed, their interpretation varies across contexts. Generative AI’s cross-border nature compounds this challenge — models trained in one country can have global social impacts, amplifying bias or misinformation internationally.

---

## Proposed Ethical Framework

Addressing these challenges requires an integrated model of **regulation, professional responsibility, and global collaboration**:

1. **Clear Ethical Guidelines:**  
   Adopt international frameworks such as the OECD AI Principles (OECD, 2019) and UNESCO’s *Recommendation on the Ethics of Artificial Intelligence* (UNESCO, 2021).  
2. **Regulatory Oversight:**  
   Establish legal enforcement and independent audits for high-risk AI systems (Radanliev et al., 2025).  
3. **Transparency and Explainability:**  
   Develop explainable AI systems to enhance trust and accountability (Hagendorff, 2024).  
4. **Inclusivity and Equity:**  
   Involve diverse social, cultural, and gender perspectives in AI development (Papagiannidis et al., 2025).  
5. **Professional Responsibility:**  
   Encourage computing professionals to adhere to ethical codes, pursue continuous education, and advocate for responsible AI (Deckard, 2023).  
6. **Public Education and Awareness:**  
   Promote digital literacy so users can critically assess AI-generated content (Dwivedi et al., 2023).

---

## Implications for Computing Professionals

- **Duty of Care:** Professionals must prevent harm by ensuring AI systems are safe, unbiased, and transparent (Deckard, 2023).  
- **Licensing and Certification:** Formalised accreditation could help uphold ethical standards (Al-kfairy, 2024).  
- **Leadership and Advocacy:** Professionals should foster ethical cultures within organisations, bridging technical and social domains (Kijewski, 2024).

---

## Conclusion

Generative AI is a transformative technology that challenges traditional legal, social, and ethical frameworks. Correa et al. (2023) identify fragmentation in global AI ethics, while Deckard (2023) calls for actionable principles. A comprehensive response demands robust regulation, professional accountability, shared ethical standards, and public engagement.  

Computing professionals play a pivotal role in guiding AI’s future — ensuring innovation aligns with human values. By prioritising transparency, fairness, and human-centred design, the AI community can realise the benefits of generative AI while minimising harm.

---

## Reflection

**What?**  
This activity encouraged me to evaluate emerging ethical challenges linked to AI and automation.  

**So what?**  
I gained insight into how professional codes like the ACM and BCS can guide responsible use of generative technologies.  

**Now what?**  
I will continue monitoring developments in AI ethics and integrate responsible design principles into future projects.

---

## References

Al-kfairy, M. (2024) ‘Ethical Challenges and Solutions of Generative AI’, *Information*, 11(3), p. 58.  
Available at: [https://www.mdpi.com/2227-9709/11/3/58](https://www.mdpi.com/2227-9709/11/3/58) (Accessed: 05 September 2025).

Correa, N.K., et al. (2023) ‘Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance’, *Patterns*, 4(10).  
Available at: [https://doi.org/10.1016/j.patter.2023.100857](https://doi.org/10.1016/j.patter.2023.100857) (Accessed: 05 September 2025).

Deckard, R. (2023) ‘What are ethics in AI?’, *BCS*.  
Available at: [https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/](https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/) (Accessed: 05 September 2025).

Dwivedi, Y.K., et al. (2023) ‘Ethical AI for Teaching and Learning’, *Cornell University*.  
Available at: [https://teaching.cornell.edu/generative-artificial-intelligence/ethical-ai-teaching-and-learning](https://teaching.cornell.edu/generative-artificial-intelligence/ethical-ai-teaching-and-learning) (Accessed: 05 September 2025).

Hagendorff, T. (2024) ‘Mapping the Ethics of Generative AI: A Comprehensive Review’, *Minds and Machines*, 34, pp. 217–245.  
Available at: [https://link.springer.com/article/10.1007/s11023-024-09694-w](https://link.springer.com/article/10.1007/s11023-024-09694-w) (Accessed: 05 September 2025).

Kijewski, S. (2024) ‘The Rise of Checkbox AI Ethics: A Review’, *PMC*.  
Available at: [https://pmc.ncbi.nlm.nih.gov/articles/PMC12103313/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12103313/) (Accessed: 05 September 2025).

NIST (2023) *AI Risk Management Framework.*  
Available at: [https://www.nist.gov/itl/ai-risk-management-framework](https://www.nist.gov/itl/ai-risk-management-framework) (Accessed: 05 September 2025).

OECD (2019) *OECD Principles on Artificial Intelligence.*  
Available at: [https://www.oecd.org/en/topics/sub-issues/ai-principles.html](https://www.oecd.org/en/topics/sub-issues/ai-principles.html) (Accessed: 05 September 2025).

Papagiannidis, S., et al. (2025) ‘Responsible artificial intelligence governance: A review’, *Technological Forecasting and Social Change*, 195, p. 122987.  
Available at: [https://www.sciencedirect.com/science/article/pii/S0963868724000672](https://www.sciencedirect.com/science/article/pii/S0963868724000672) (Accessed: 05 September 2025).

Radanliev, P., et al. (2025) ‘AI Ethics: Integrating Transparency, Fairness, and Privacy’, *AI & Society*, 40, pp. 105–120.  
Available at: [https://www.tandfonline.com/doi/full/10.1080/08839514.2025.2463722](https://www.tandfonline.com/doi/full/10.1080/08839514.2025.2463722) (A
